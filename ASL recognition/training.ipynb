{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data:\n",
    "https://www.kaggle.com/datasets/grassknoted/asl-alphabet/download?datasetVersionNumber=1\n",
    "'''\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers,losses,optimizers\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINPATH=\"D:\\\\df\\\\ai\\\\asl\\\\asl_alphabet_train\\\\asl_alphabet_train\\\\\"\n",
    "TESTPATH=\"D:\\\\df\\\\ai\\\\asl\\\\asl_alphabet_test\\\\asl_alphabet_test\\\\\"\n",
    "IMAGE_WIDTH=IMAGE_HEIGHT=224\n",
    "BATCH_SIZE=64\n",
    "NUM_EPOCHS=5\n",
    "LR=3e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'del', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'nothing', 'O', 'P', 'Q', 'R', 'S', 'space', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              images output\n",
       "0  D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...      A\n",
       "1  D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...      A\n",
       "2  D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...      A\n",
       "3  D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...      A\n",
       "4  D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...      A\n",
       "5  D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...      A\n",
       "6  D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...      A\n",
       "7  D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...      A\n",
       "8  D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...      A\n",
       "9  D:\\df\\ai\\asl\\asl_alphabet_train\\asl_alphabet_t...      A"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "classes=os.listdir(TRAINPATH)\n",
    "print(classes)\n",
    "images=[]\n",
    "outputs=[]\n",
    "\n",
    "for letter in classes:\n",
    "    for image in os.listdir(TRAINPATH+letter):\n",
    "        images.append(TRAINPATH+letter+'\\\\'+image)\n",
    "        outputs.append(letter)\n",
    "trainframe=pd.DataFrame({\"images\":images,\"output\":outputs})\n",
    "images.clear()\n",
    "outputs.clear()\n",
    "\n",
    "for test in os.listdir(TESTPATH):\n",
    "    images.append(TESTPATH+test)\n",
    "    outputs.append(test[0])\n",
    "testframe=pd.DataFrame({\"images\":images,\"output\":outputs})\n",
    "\n",
    "trainframe.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 87000 validated image filenames belonging to 29 classes.\n",
      "Found 28 validated image filenames belonging to 28 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "valgen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "train_data=datagen.flow_from_dataframe(\n",
    "    trainframe,\n",
    "    target_size=(IMAGE_WIDTH,IMAGE_WIDTH),\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    color_mode=\"rgb\",\n",
    "    x_col=\"images\",\n",
    "    y_col=\"output\",\n",
    ")\n",
    "test_data=valgen.flow_from_dataframe(\n",
    "    testframe,\n",
    "    target_size=(IMAGE_WIDTH,IMAGE_HEIGHT),\n",
    "    shuffle=True,\n",
    "    batch_size=1,\n",
    "    class_mode='categorical',\n",
    "    color_mode=\"rgb\",\n",
    "    x_col=\"images\",\n",
    "    y_col=\"output\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "url=\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
    "download_model = hub.KerasLayer(url,input_shape=(IMAGE_WIDTH,IMAGE_WIDTH,3))\n",
    "model=keras.Sequential()\n",
    "model.add(download_model)\n",
    "model.add(layers.Dense(29,activation=\"softmax\"))\n",
    "model.compile(optimizers.Adam(LR),loss=losses.CategoricalCrossentropy(False),metrics=[\"acc\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gPU:0'):\n",
    "    model.fit(train_data,steps_per_epoch=train_data.samples // BATCH_SIZE,epochs=NUM_EPOCHS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.896551724137931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_preds=[]\n",
    "y_real=[]\n",
    "i=0\n",
    "for ds in test_data:\n",
    "    if i>28:\n",
    "        break\n",
    "    image,classe=enumerate(ds)\n",
    "    image=image[1]\n",
    "    pred=model.predict(image,verbose=\"0\")\n",
    "    y_preds.append(np.argmax(pred))\n",
    "    y_real.append(np.argmax(classe[1]))\n",
    "    i+=1\n",
    "print(\"accuracy_score:\",accuracy_score(y_real,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3663913924b1daa3d8d3926798e99031b125700758b9d2e89fd61fec1c9e6b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
